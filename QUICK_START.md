# üöÄ Quick Start Guide - Enhanced Multi-Agent Team

## What Changed?

Your multi-agent system now has **6 major new features**:

### 1. ‚úÖ Agent Selection & Presets
**Before**: All 10 agents ran every time
**Now**: Choose exactly which agents to run via checkboxes OR quick presets

### 2. üî¨ Market Research Agent **[NEW!]**
**Before**: No market analysis capability
**Now**: Comprehensive market research, competitive intelligence, and strategic recommendations

### 3. üîç Code Review Mode **[NEW!]**
**Before**: Only for new project development
**Now**: Specialized mode for analyzing existing code with optimized prompts

### 4. ‚úèÔ∏è Custom Prompts
**Before**: Hardcoded prompts for each agent
**Now**: Override prompts for any agent with custom instructions

### 5. ü§ñ Model Selection & Intelligent Fallback
**Before**: All agents used same model (Haiku)
**Now**:
- **5 Smart Presets** (Speed/Balanced/Quality/Premium/Budget)
- **Per-agent model override** for fine control
- **Automatic fallback** when rate limits hit (Opus ‚Üí Sonnet ‚Üí Haiku)
- **Retry with exponential backoff** for network errors
- **Save 60-80% on API costs** with strategic model mixing

### 6. üì§ Export Functionality
**Before**: Results only visible in UI
**Now**: Export to JSON, Markdown, CSV + individual agent exports

---

## Installation (30 seconds)

```bash
# 1. Install dependencies
pip install gradio crewai crewai-tools gitpython anthropic

# 2. Set API key (Windows)
set ANTHROPIC_API_KEY=your_key_here

# 3. Run the app
python multi_agent_team.py

# 4. Open browser to http://127.0.0.1:7860
```

---

## Basic Usage (4 Steps)

### Step 1: Describe Your Project
```
Example: "Build a mobile fitness tracker app with workout logging,
progress charts, and social sharing features."
```

### Step 2: Select Agents
**Option A: Use Preset (Recommended)**
- Choose from Agent Preset dropdown:
  - **New Project Development** (default)
  - **Code Review** (for existing code)
  - **Market Research** (validate ideas)
  - **Full Stack Development** (comprehensive)
  - **Security Audit** (security focus)
  - **Architecture Review** (design focus)

**Option B: Custom Selection**
- Select "Custom Selection" preset
- Manually check agents you want:
  - ‚úÖ PM (Project Manager)
  - ‚úÖ Memory (Recall learnings)
  - ‚úÖ Research (Market analysis)
  - ‚úÖ Ideas (Generate features)
  - ‚úÖ Designs (Create UI/UX)
  - ‚úÖ QA (Test & validate)

### Step 3: Choose Model Preset
Select performance vs. quality trade-off:
- **Speed (All Haiku)** - Fastest, cheapest (~$0.01)
- **Balanced (All Sonnet)** - Recommended for most work (~$0.15)
- **Quality (Critical=Opus)** - Best results (~$0.25)
- **Premium (All Opus)** - Maximum quality (~$0.75)
- **Budget** - Minimal cost (~$0.03)

**Don't overthink it - Balanced is great for 90% of projects!**

### Step 4: (Optional) Configure Execution Priority
Want to control the order agents run?

- Click "Configure Agent Execution Order" accordion
- Lower number = runs first (e.g., 1 before 2)
- Same number = can run in parallel
- **Default order works great** - only customize if needed

**Default execution order:**
1. Memory, PM (gather context and plan)
2. Research (market analysis)
3. Ideas (feature generation)
4. Designs (UI/UX creation)
5. iOS, Android, Web (implementation)
6. Senior (code review)
7. QA (testing)
8. Verifier (final checks)

**Example custom order:**
- Want research and ideas to start together? Set both to priority 1
- Want PM to wait for research? Set PM=3, Research=1
- Want all engineers to run after all planning? Keep defaults

### Step 5: Click "Run Team"
Results will appear in the Agent Outputs section below.

---

## Model Selection Deep Dive

### Why It Matters
Different models have **drastically different costs**:
- Opus: $15 per million tokens (slow, excellent)
- Sonnet: $3 per million tokens (medium, great)
- Haiku: $0.25 per million tokens (fast, good)

**Smart mixing saves 60-80% on costs!**

### Which Preset Should I Use?

**Speed** - When you need:
- Quick prototyping
- Brainstorming sessions
- Testing the system
- Draft outputs

**Balanced** ‚≠ê - When you need:
- Most production work
- Standard quality requirements
- Good balance of cost/quality

**Quality** - When you need:
- Important projects
- High-stakes decisions
- Critical code reviews
- Enterprise deliverables

**Premium** - When you need:
- Maximum possible quality
- Mission-critical work
- Complex reasoning required

**Budget** - When you need:
- Minimum cost
- Non-critical exploration
- High volume runs

### Advanced: Per-Agent Override

Want fine control? Use **"Advanced: Per-Agent Model Override"**:

1. Choose a preset as starting point
2. Click the accordion
3. Override specific agents:
   - PM ‚Üí Haiku (simple planning)
   - Ideas ‚Üí Sonnet (creative work)
   - Senior ‚Üí Opus (critical review)
   - Verifier ‚Üí Opus (final check)

**Example Strategic Mix**:
```
Simple tasks ‚Üí Haiku
Standard work ‚Üí Sonnet
Critical decisions ‚Üí Opus
Result: 67% cost savings vs all Opus!
```

---

## üõ°Ô∏è Intelligent Fallback System

### What Happens When Rate Limits Hit?

The system **automatically handles rate limits** with zero user intervention:

```
Scenario: You select Opus but hit rate limit

1. Agent tries with Opus
2. ‚ö†Ô∏è Rate limit detected (429 error)
3. ‚Üí Auto-fallback to Sonnet
4. Wait 5 seconds
5. ‚úì Retry succeeds with Sonnet
6. Continue execution seamlessly
```

### Fallback Chain

```
Opus (rate limited)
  ‚Üì
Sonnet (fallback)
  ‚Üì
Haiku (final fallback)
  ‚Üì
Error (only if all fail)
```

### Real Example Log

```
[14:30:00] Senior: Attempt 1/3 with Opus
[14:30:05] Senior: ‚ö†Ô∏è Rate limit hit with Opus
[14:30:05] Senior: ‚Üí Falling back to Sonnet
[14:30:05] Senior: Waiting 5s before retry...
[14:30:10] Senior: Attempt 2/3 with Sonnet
[14:30:15] Senior: ‚úì Succeeded after 2 attempts
```

### Benefits

‚úÖ **No manual intervention needed**
‚úÖ **Execution continues automatically**
‚úÖ **Transparent logging of all retries**
‚úÖ **Exponential backoff prevents hammering API**
‚úÖ **Graceful degradation (better than failure!)**

**You can confidently use Opus knowing the system will fallback if needed!**

---

## Agent Selection Guide

### üî¨ Market Research & Validation **[NEW!]**
**Preset**: Market Research
**Agents**: Memory, Research, Ideas, Senior
**Time**: ~4-5 minutes
**Output**: Market analysis + competitive intelligence + strategic recommendations
**Use Code Review Mode**: No

### üîç Code Review & Security Audit **[NEW!]**
**Preset**: Code Review
**Agents**: Senior, QA, Verifier
**Time**: ~3-4 minutes
**Output**: Architecture review + test strategy + security audit
**Use Code Review Mode**: Yes ‚úì

### üöÄ New Project Development
**Preset**: New Project Development (default)
**Agents**: PM, Memory, Research, Ideas, Designs, QA
**Time**: ~8-10 minutes
**Output**: Complete planning with market insights + designs + test plan
**Use Code Review Mode**: No

### üíª Full Development (Complete)
**Preset**: Full Stack Development
**Agents**: All 11 agents
**Time**: ~18-25 minutes
**Output**: Complete project lifecycle from market research to testing
**Use Code Review Mode**: No

### üõ°Ô∏è Security Audit
**Preset**: Security Audit
**Agents**: Senior, Verifier
**Time**: ~2-3 minutes
**Output**: Security analysis + compliance checks
**Use Code Review Mode**: Yes ‚úì

### üèóÔ∏è Architecture Review
**Preset**: Architecture Review
**Agents**: Senior, Verifier
**Time**: ~2-3 minutes
**Output**: Design patterns + architecture review
**Use Code Review Mode**: Yes ‚úì

### üéØ Quick Planning (Fast)
**Preset**: Custom Selection
**Agents**: PM, Memory, Ideas
**Time**: ~2 minutes
**Output**: Sprint plan + feature ideas
**Use Code Review Mode**: No

### üì± Platform-Specific
**Preset**: Custom Selection
**Agents**: PM, Research, Ideas, iOS (or Android/Web), QA
**Time**: ~6-8 minutes
**Output**: Platform-specific implementation with market context
**Use Code Review Mode**: No

---

## üî¨ Using the Research Agent

### What Does It Analyze?

The Research agent provides comprehensive market intelligence:

1. **Market Size & Opportunity**: TAM/SAM/SOM analysis where applicable
2. **Target Audience**: User personas and demographics
3. **Competitive Landscape**: Direct and indirect competitors
4. **Competitor Analysis**: Strengths, weaknesses, and gaps
5. **Market Opportunities**: Unmet needs and white spaces
6. **Required Features**: Must-have features to be competitive
7. **Differentiation Strategy**: How to stand out from competition
8. **Go-to-Market Recommendations**: Strategic launch approach
9. **Challenges & Risks**: Potential obstacles to success
10. **Strategic Recommendations**: Data-driven action items

### When to Use Research Agent?

‚úÖ **Use Research when:**
- Starting a new project or business
- Validating a product idea
- Understanding competitive landscape
- Defining product strategy
- Seeking market differentiation

‚ùå **Skip Research when:**
- Building internal tools (no market competition)
- Working on minor feature updates
- Doing code reviews or bug fixes
- Time is critical and market context exists

### Example: Market Research Workflow

**Step 1**: Select "Market Research" preset
**Step 2**: Enter your idea:
```
"AI-powered meal planning app that generates shopping lists
based on dietary preferences and local grocery store prices."
```
**Step 3**: Click "Run Team"
**Step 4**: Review outputs:
- **Memory**: Recalls similar projects analyzed
- **Research**: Market size, competitors (MyFitnessPal, Mealime), differentiation strategy
- **Ideas**: Feature recommendations based on market gaps
- **Senior**: Technical feasibility and architecture suggestions

---

## üîç Using Code Review Mode

### What Changes in Code Review Mode?

When enabled, three agents get specialized prompts:

**Senior Agent** ‚Üí Comprehensive code review covering:
- Architecture patterns and adherence
- Code organization and modularity
- Performance and scalability concerns
- Security vulnerabilities
- Best practices compliance
- Technical debt identification

**QA Agent** ‚Üí Test strategy creation including:
- Test coverage analysis
- Missing test cases
- Testing framework recommendations
- Integration and E2E test needs
- Performance testing requirements
- Edge case identification

**Verifier Agent** ‚Üí Security audit focusing on:
- OWASP Top 10 vulnerabilities
- Authentication and authorization issues
- Data validation and sanitization
- Dependency security
- Compliance requirements (GDPR, etc.)
- Infrastructure security

### When to Use Code Review Mode?

‚úÖ **Use Code Review Mode when:**
- Reviewing pull requests
- Auditing existing codebase
- Pre-deployment security checks
- Architecture reviews
- Technical debt assessment
- Onboarding to new codebase

‚ùå **Don't use Code Review Mode when:**
- Starting new projects from scratch
- Doing market research
- Creating designs and wireframes
- No code exists yet

### Example: Code Review Workflow

**Step 1**: Select "Code Review" preset (Auto-enables Code Review Mode)
**Step 2**: Describe the code:
```
"Review the authentication system in server/src/routes/auth-complete.ts
Check for security issues, error handling, and best practices."
```
**Step 3**: Click "Run Team"
**Step 4**: Review findings:
- **Senior**: Architecture and pattern issues
- **QA**: Test coverage gaps and recommended test cases
- **Verifier**: Security vulnerabilities and compliance issues

---

## Custom Prompts (Advanced)

### When to Use Custom Prompts?
- You need domain-specific expertise
- You want specific output format
- You're working on a niche project
- Default prompts are too generic

### How to Use
1. Click **"Override Agent Prompts"** accordion
2. Enter custom prompt for specific agents
3. Use `{project_description}` as placeholder

### Example: Custom PM Prompt
```
Create a 3-sprint plan for: {project_description}

Requirements:
- Sprint 1: Core MVP features only
- Sprint 2: User testing and refinement
- Sprint 3: Polish and launch prep

Format as a table with columns: Sprint, Features, Story Points
```

### Example: Custom iOS Prompt
```
Build SwiftUI code for: {project_description}

Requirements:
- Use MVVM architecture
- Include unit tests
- Add detailed code comments
- Follow Apple HIG guidelines
```

---

## Export Guide

### Auto-Export (Recommended)
1. ‚úÖ Enable "Auto-export results" checkbox
2. Run the team
3. Files are automatically saved to `./exports/`

### Manual Export
After running the team:
- Click **"JSON"** for structured data
- Click **"Markdown"** for readable reports
- Click **"CSV"** for spreadsheet format
- Click **"üì¶ Export All Formats"** for everything

### Individual Agent Export
- Scroll to any agent's output
- Click **"Export {AgentName}"** button
- Get a dedicated markdown file for that agent

### What's in the Exports?

**JSON** - Best for:
- Programmatic processing
- Data analysis
- Integration with other tools

**Markdown** - Best for:
- Sharing with team
- Documentation
- Human reading

**CSV** - Best for:
- Spreadsheet analysis
- Data visualization
- Reporting

---

## Real-World Examples

### Example 1: Market Research for New App **[NEW!]**

**Project Description:**
```
AI-powered personal finance app that analyzes spending patterns
and provides automated savings recommendations. Target millennials
and Gen Z who struggle with budgeting.
```

**Agent Preset:** Market Research
**Code Review Mode:** Disabled
**Model Preset:** Balanced

**Result:**
- **Memory**: Recalled similar fintech projects analyzed
- **Research**: Market size ($10B+), competitors (Mint, YNAB, Copilot), key differentiator = AI automation
- **Ideas**: Must-have features (bank integration, spending alerts, goal tracking)
- **Senior**: Tech stack recommendations (Plaid API, cloud infrastructure)

**Time:** ~5 minutes | **Cost:** ~$0.08

---

### Example 2: Code Review for Authentication System **[NEW!]**

**Project Description:**
```
Review the authentication system in server/src/routes/auth-complete.ts
and server/src/middleware/security.ts. Check for security vulnerabilities,
proper error handling, and adherence to best practices.
```

**Agent Preset:** Code Review
**Code Review Mode:** Enabled ‚úì
**Model Preset:** Quality (Critical=Opus)

**Result:**
- **Senior**: Found 3 architecture issues (token refresh logic, password reset flow)
- **QA**: Identified 12 missing test cases (edge cases, error scenarios)
- **Verifier**: Flagged 2 security concerns (CSRF protection, rate limiting)

**Time:** ~4 minutes | **Cost:** ~$0.15

---

### Example 3: E-commerce App with Market Insights

**Project Description:**
```
Build a mobile e-commerce app for sustainable fashion.
Features: product catalog, cart, checkout, user reviews, wishlist.
Target: iOS and Android, budget-conscious millennials.
```

**Agent Preset:** Full Stack Development
**Code Review Mode:** Disabled
**Model Preset:** Balanced

**Agent Results:**
- **Research**: Market analysis (sustainable fashion = $6.5B market, growing 9% YoY)
- **PM**: 4-sprint implementation plan
- **Ideas**: Sustainability scoring, carbon offset integration, eco-friendly packaging
- **Designs**: Earthy UI design, product sustainability badges
- **iOS/Android/Web**: Code samples with sustainable commerce features
- **QA**: Test plan covering all platforms
- **Verifier**: Final verification + security checklist

**Time:** ~22 minutes | **Cost:** ~$0.25

---

### Example 4: Quick SaaS Dashboard Prototype

**Project Description:**
```
Create an analytics dashboard for SaaS metrics.
Show MRR, churn rate, user growth, feature usage.
Web-based, real-time updates, export to PDF.
```

**Agent Preset:** Custom Selection (PM, Ideas, Designs, Web, QA)
**Code Review Mode:** Disabled
**Model Preset:** Speed (All Haiku)

**Result:**
- **PM**: Sprint plan with prioritized features
- **Ideas**: Dashboard widgets and visualization types
- **Designs**: Wireframes for dashboard layout
- **Web**: React + Recharts implementation with code samples
- **QA**: Test scenarios for real-time updates

**Time:** ~7 minutes | **Cost:** ~$0.02

---

### Example 5: Security Audit of Existing Codebase **[NEW!]**

**Project Description:**
```
Security audit of the entire authentication and authorization system.
Check for OWASP Top 10 vulnerabilities, validate JWT implementation,
review session management and password security.
```

**Agent Preset:** Security Audit
**Code Review Mode:** Enabled ‚úì
**Model Preset:** Premium (All Opus)

**Result:**
- **Senior**: Deep architecture review, identified session storage issues
- **Verifier**: Comprehensive security audit with OWASP checklist, found XSS vulnerability

**Time:** ~3 minutes | **Cost:** ~$0.12

---

## Troubleshooting

### ‚ùå "Error: Project description cannot be empty"
**Fix**: Enter a project description in the text box

### ‚ùå "Error: Please select at least one agent"
**Fix**: Check at least one agent checkbox

### ‚ùå "Error creating crew"
**Fix**:
1. Check API key: `echo %ANTHROPIC_API_KEY%`
2. Verify internet connection
3. Check API key permissions

### ‚ö†Ô∏è "Export failed"
**Fix**:
1. Check `./exports/` directory exists
2. Verify write permissions
3. Ensure enough disk space

### üêå "Running too slow"
**Fix**:
1. Select fewer agents
2. Reduce `RATE_LIMIT_DELAY` in code
3. Use faster model (haiku vs opus)

---

## Tips & Tricks

### üí° Tip 1: Use Memory Agent
Run projects multiple times to build up organizational memory.
The Memory agent recalls past learnings automatically.

### üí° Tip 2: Iterate with Feedback
Use "Reject and Rerun" with feedback to refine outputs:
1. First run: See initial results
2. Add feedback: "Make it more mobile-friendly"
3. Rerun: Get refined results

### üí° Tip 3: Save Good Prompts
Keep a library of custom prompts that work well.
Copy-paste them for similar projects.

### üí° Tip 4: Export Everything
Enable auto-export for important runs.
You can always delete exports later, but can't recreate them.

### üí° Tip 5: Review System Logs
Check the "System" agent output for execution details and warnings.

### üí° Tip 6: Combine Agents Strategically
- Memory + Research = Market-aware insights
- Research + Ideas = Competitive feature sets
- Ideas + Designs = Visual feature specs
- Senior + Verifier = Quality assurance

### üí° Tip 7: Use Research Agent Early **[NEW!]**
Run Research agent before building anything.
Understanding the market prevents wasted effort on the wrong features.

### üí° Tip 8: Enable Code Review Mode for PRs **[NEW!]**
Use Code Review preset + Code Review Mode enabled for all pull request reviews.
Catches security issues and test gaps before merge.

### üí° Tip 9: Mix Model Presets Strategically
- Quick iterations ‚Üí Speed preset
- Important decisions ‚Üí Quality preset
- Final reviews ‚Üí Premium preset
Save 60-80% on costs vs always using Opus!

### üí° Tip 10: Use Presets for Consistency
Agent presets ensure consistent workflows across your team.
Everyone uses the same agents for the same tasks.

---

## Keyboard Shortcuts

*None yet - fully GUI-based*

Consider opening feature request for keyboard shortcuts!

---

## Next Steps

### Beginner
1. ‚úÖ Run with default settings and see what happens
2. ‚úÖ Try different agent combinations
3. ‚úÖ Export results and review formats

### Intermediate
1. ‚úÖ Write custom prompts for specific agents
2. ‚úÖ Build up memory with multiple runs
3. ‚úÖ Use "Reject and Rerun" workflow

### Advanced
1. ‚úÖ Customize agent definitions in code
2. ‚úÖ Add new agents for your domain
3. ‚úÖ Integrate exports with your workflow
4. ‚úÖ Modify default prompts globally

---

## Getting Help

**Read the full docs**: `README_ENHANCED.md`
**Test the system**: `python test_enhanced_features.py`
**Check configuration**: Review `multi_agent_team.py` lines 1-110

---

## Comparison: Before vs After

| Feature | Before | After |
|---------|---------|--------|
| Agents | 10 agents | 11 agents (+ Research) |
| Agent Selection | All 10 always run | Choose any combination + presets |
| Market Research | None | Comprehensive market & competitive analysis |
| Code Review | Not optimized | Dedicated Code Review Mode |
| Model Selection | Fixed Haiku | 5 presets + per-agent override |
| Intelligent Fallback | None | Auto-fallback on rate limits (Opus‚ÜíSonnet‚ÜíHaiku) |
| Custom Prompts | Hardcoded | Per-agent customization |
| Export | UI only | JSON, MD, CSV + individual |
| Error Handling | Basic | Comprehensive try-catch + retry logic |
| UI | Simple | Organized with presets & accordions |
| Phase Control | Buggy (undefined var) | Fixed with 4 phases |
| API Key | Hardcoded (security risk) | Environment variable |
| Documentation | Minimal | Complete guide with examples |

---

## Performance Benchmarks

*(Approximate times on standard API tier)*

| Configuration | Agents | Time | Cost (Speed) | Cost (Balanced) | Cost (Quality) |
|--------------|--------|------|--------------|-----------------|----------------|
| Market Research | 4 | ~4 min | $0.02 | $0.08 | $0.12 |
| Code Review | 3 | ~3 min | $0.01 | $0.06 | $0.15 |
| Quick Planning | 3 | ~2 min | $0.01 | $0.05 | $0.08 |
| Design Phase | 6 | ~8 min | $0.03 | $0.12 | $0.18 |
| Platform Dev | 5 | ~7 min | $0.03 | $0.10 | $0.15 |
| Full Run | 11 | ~22 min | $0.06 | $0.25 | $0.45 |

*Cost estimates with Speed (Haiku), Balanced (Sonnet), Quality (Critical=Opus) presets

---

## Success Checklist

Before running your first project:

- [ ] Python 3.8+ installed
- [ ] All dependencies installed (`pip install ...`)
- [ ] ANTHROPIC_API_KEY environment variable set
- [ ] Ran `python test_enhanced_features.py` successfully
- [ ] Reviewed this Quick Start guide
- [ ] Know which agents to select for your use case

Ready? Run: `python multi_agent_team.py` üöÄ

---

**Happy Building!** üéâ

If something isn't working, check the Troubleshooting section or review `README_ENHANCED.md` for detailed documentation.
